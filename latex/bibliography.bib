@book{sutton2018reinforcement,
  title={Reinforcement Learning: An Introduction},
  author={Sutton, R.S. and Barto, A.G.},
  isbn={9780262039246},
  lccn={2018023826},
  series={Adaptive Computation and Machine Learning series},
  url={https://books.google.com.hk/books?id=sWV0DwAAQBAJ},
  year={2018},
  publisher={MIT Press}
}
@misc{openaispinningup,
    title={OpenAI Spinning Up},
    author={Josh Achiam},
    url={https://spinningup.openai.com/en/latest/index.html},
    year={2018}
}
@article{SUTTON1999181,
title = "Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning",
journal = "Artificial Intelligence",
volume = "112",
number = "1",
pages = "181 - 211",
year = "1999",
issn = "0004-3702",
doi = "https://doi.org/10.1016/S0004-3702(99)00052-1",
url = "http://www.sciencedirect.com/science/article/pii/S0004370299000521",
author = "Richard S. Sutton and Doina Precup and Satinder Singh",
keywords = "Temporal abstraction, Reinforcement learning, Markov decision processes, Options, Macros, Macroactions, Subgoals, Intra-option learning, Hierarchical planning, Semi-Markov decision processes"
}
@article{learningoptionsinrl,
    author="Stolle, Martin and Precup, Doina",
    editor="Koenig, Sven and Holte, Robert C.",
    title="Learning Options in Reinforcement Learning",
    booktitle="Abstraction, Reformulation, and Approximation",
    year="2002",
    publisher="Springer Berlin Heidelberg",
    address="Berlin, Heidelberg",
    pages="212--223",
    abstract="Temporally extended actions (e.g., macro actions) have proven very useful for speeding up learning, ensuring robustness and building prior knowledge into AI systems. The options framework (Precup, 2000; Sutton, Precup {\&} Singh, 1999) provides a natural way of incorporating such actions into reinforcement learning systems, but leaves open the issue of how good options might be identified. In this paper, we empirically explore a simple approach to creating options. The underlying assumption is that the agent will be asked to perform different goal-achievement tasks in an environment that is othertherwise the same over time. Our approach is based on the intuition that states that are frequently visited on system trajectories, could prove to be useful subgoals (e.g., McGovern {\&} Barto, 2001; Iba, 1989).",
    isbn="978-3-540-45622-3"
}
@article{smdp,
author = {Bradtke, Steven and Duff, Michael},
year = {1994},
month = {12},
pages = {},
title = {Reinforcement Learning Methods for Continuous-Time Markov Decision Problems}
}
@inproceedings{intraoplearn,
author = {Sutton, Richard and Precup, Doina and Singh, Satinder},
year = {1998},
month = {01},
pages = {556-564},
title = {Intra-Option Learning about Temporally Abstract Actions.}
}
@misc{bacon2016optioncritic,
    title={The Option-Critic Architecture},
    author={Pierre-Luc Bacon and Jean Harb and Doina Precup},
    year={2016},
    eprint={1609.05140},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}
@misc{Konda00actor-criticalgorithms,
    author = {Vijay Konda and John Tsitsiklis},
    title = {Actor-Critic Algorithms},
    booktitle = {SIAM Journal on Control and Optimization},
    year = {2000},
    pages = {1008--1014},
    publisher = {MIT Press}
}
@misc{harb2017waiting,
    title={When Waiting is not an Option : Learning Options with a Deliberation Cost},
    author={Jean Harb and Pierre-Luc Bacon and Martin Klissarov and Doina Precup},
    year={2017},
    eprint={1709.04571},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}
@misc{khetarpal2020options,
    title={Options of Interest: Temporal Abstraction with Interest Functions},
    author={Khimya Khetarpal and Martin Klissarov and Maxime Chevalier-Boisvert and Pierre-Luc Bacon and Doina Precup},
    year={2020},
    eprint={2001.00271},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
@misc{harutyunyan2019termination,
    title={The Termination Critic},
    author={Anna Harutyunyan and Will Dabney and Diana Borsa and Nicolas Heess and Remi Munos and Doina Precup},
    year={2019},
    eprint={1902.09996},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}
@misc{attentionoptioncritic,
    title={Attention Option-Critic},
    author={Raviteja Chunduru and Doina Precup},
    year={2020}
}
@InProceedings{adaboost,
author="Freund, Yoav
and Schapire, Robert E.",
editor="Vit{\'a}nyi, Paul",
title="A desicion-theoretic generalization of on-line learning and an application to boosting",
booktitle="Computational Learning Theory",
year="1995",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="23--37"
}
@misc{zhang2018ace,
    title={ACE: An Actor Ensemble Algorithm for Continuous Control with Tree Search},
    author={Shangtong Zhang and Hao Chen and Hengshuai Yao},
    year={2018},
    eprint={1811.02696},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
@misc{iocrepo,
  author = {Khimya Khetarpal},
  title = {Interest Option-Critic repository},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/kkhetarpal/ioc}}
}
@misc{ocrepo,
  author = {Jean Harb},
  title = {Option-Critic repository},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/jeanharb/option_critic}}
}